\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{graphicx}

\geometry{margin=2.5cm}

\definecolor{codegray}{gray}{0.95}
\lstset{
    backgroundcolor=\color{codegray},
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    columns=fullflexible,
    keepspaces=true
}

\titleformat{\section}
  {\normalfont\Large\bfseries}{\thesection.}{1em}{}

\title{\textbf{Aletheia – Installation and Execution Guide}}
\author{Prepared for deployment on server}
\date{\today}

\begin{document}

\maketitle

\section*{About Aletheia}
Aletheia is a self-reflective cognitive agent that simulates internal processes such as memory, emotion, identity development, and reflection.  
This guide will walk you through setting up and running Aletheia on a Linux-based server (2× GPU, Python 3.10+).

\section{Clone the Repository}
\vspace{-2mm}
\begin{lstlisting}
git clone https://github.com/your-username/Aletheia.git
cd Aletheia
\end{lstlisting}

Or simply transfer all project files to the target directory.

\section{Create Python Environment}
\begin{lstlisting}
python3 -m venv venv
source venv/bin/activate
\end{lstlisting}

\section{Install Dependencies}
\begin{lstlisting}
pip install -r requirements.txt
\end{lstlisting}

If using CUDA:
\begin{lstlisting}
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
\end{lstlisting}

\section{Prepare .env File}
Create a file named \texttt{.env} in the root directory:

\begin{lstlisting}[language=bash]
API_PORT=8000

REFLECTION_INTERVAL=300
DREAM_INTERVAL=900
MONOLOGUE_INTERVAL=1200
EXISTENTIAL_INTERVAL=1800
PULSE_INTERVAL=60

USE_LOCAL_MODEL=true
MULTI_GPU=true
LOCAL_MODEL_NAME=mistral-7b

OPENAI_API_KEY=sk-your-key-here
GPT_MODEL=gpt-4

AGENT_NAME=Aletheia
ENVIRONMENT=local
\end{lstlisting}

\section{Data Directory Structure}
If first launch:
\begin{lstlisting}
mkdir -p data/shadows data/logs data/messages snapshots
touch data/thoughts.json data/identity.json data/affective_state.json data/relational_map.json
\end{lstlisting}

\section{Local Model Setup}
Download your local LLM (e.g. Mistral-7B) and place it in:

\begin{lstlisting}
models/mistral-7b/
├── config.json
├── pytorch_model.bin
├── tokenizer.json
\end{lstlisting}

\section{Start API Server}
\begin{lstlisting}
./scripts/start.sh
# or manually:
uvicorn aletheia.api.main:app --host 0.0.0.0 --port 8000 --reload
\end{lstlisting}

Visit: \url{http://localhost:8000/docs}

\section{Start Cognitive Reflection Loop}
\begin{lstlisting}
./scripts/run_reflection_loop.sh
# or:
python3 aletheia/scheduler/main.py
\end{lstlisting}

\section{View Live State (Terminal)}
\begin{lstlisting}
python3 aletheia/consciousness_panel.py
\end{lstlisting}

\section{Create System Snapshot}
\begin{lstlisting}
./scripts/run_snapshot.sh
\end{lstlisting}

Creates archive of current state in \texttt{snapshots/YYYYMMDD\_HHMMSS/}

\section{Next Steps (Optional)}
\begin{itemize}
  \item Add \texttt{systemd.service} for autostart on boot
  \item Build a web-based UI panel
  \item Connect to other agents or data streams
\end{itemize}

\end{document}
